{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Split Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 251\n",
      "Training set size: 200\n",
      "Validation set size: 25\n",
      "Test set size: 26\n",
      "Training set label counts: {'positive': 88, 'negative': 112}\n",
      "Validation set label counts: {'positive': 13, 'negative': 12}\n",
      "Test set label counts: {'positive': 10, 'negative': 16}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define transformations (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "data_dir = 'C:/Users/CaioGabrielAdernedeM/OneDrive/IPB/ipb_sistemas_inteligentes/projeto_final/train'\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Calculate split sizes\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = int(0.1 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size  # Ensure all samples are used\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Total dataset size: {dataset_size}\")\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "# Function to count labels in a dataset\n",
    "def count_labels(subset):\n",
    "    labels = [dataset.targets[idx] for idx in subset.indices]  # Get labels for the subset\n",
    "    label_counts = Counter(labels)\n",
    "    return {dataset.classes[label]: count for label, count in label_counts.items()}\n",
    "\n",
    "# Print label counts for each subset\n",
    "print(\"Training set label counts:\", count_labels(train_dataset))\n",
    "print(\"Validation set label counts:\", count_labels(val_dataset))\n",
    "print(\"Test set label counts:\", count_labels(test_dataset))\n",
    "\n",
    "# Create DataLoaders (optional, if needed for training/validation/testing)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 1 with Hidden Size: 64, Learning Rate: 0.001\n",
      "Epoch 1/5, Train Loss: 4.2276, Val Loss: 7.8351, Val Accuracy: 92.00%\n",
      "Epoch 2/5, Train Loss: 2.0698, Val Loss: 6.9877, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 2.3440, Val Loss: 4.8703, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 1.4944, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
      "Epoch 5/5, Train Loss: 2.1741, Val Loss: 2.6308, Val Accuracy: 96.00%\n",
      "Model 1 Test Accuracy: 92.31%\n",
      "\n",
      "Training Model 2 with Hidden Size: 128, Learning Rate: 0.001\n",
      "Epoch 1/5, Train Loss: 11.7614, Val Loss: 6.3868, Val Accuracy: 92.00%\n",
      "Epoch 2/5, Train Loss: 5.4236, Val Loss: 13.9766, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 2.1285, Val Loss: 8.0812, Val Accuracy: 88.00%\n",
      "Epoch 4/5, Train Loss: 1.8741, Val Loss: 13.5654, Val Accuracy: 92.00%\n",
      "Epoch 5/5, Train Loss: 2.0365, Val Loss: 4.5869, Val Accuracy: 96.00%\n",
      "Model 2 Test Accuracy: 92.31%\n",
      "\n",
      "Training Model 3 with Hidden Size: 256, Learning Rate: 0.001\n",
      "Epoch 1/5, Train Loss: 18.9463, Val Loss: 23.1944, Val Accuracy: 84.00%\n",
      "Epoch 2/5, Train Loss: 14.0491, Val Loss: 0.7351, Val Accuracy: 96.00%\n",
      "Epoch 3/5, Train Loss: 12.5152, Val Loss: 10.3812, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 3.2670, Val Loss: 19.8775, Val Accuracy: 92.00%\n",
      "Epoch 5/5, Train Loss: 3.0838, Val Loss: 10.9213, Val Accuracy: 92.00%\n",
      "Model 3 Test Accuracy: 88.46%\n",
      "\n",
      "Training Model 4 with Hidden Size: 64, Learning Rate: 0.0005\n",
      "Epoch 1/5, Train Loss: 3.5238, Val Loss: 0.0002, Val Accuracy: 100.00%\n",
      "Epoch 2/5, Train Loss: 0.8542, Val Loss: 7.7072, Val Accuracy: 88.00%\n",
      "Epoch 3/5, Train Loss: 1.7903, Val Loss: 2.4669, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 0.7363, Val Loss: 1.1100, Val Accuracy: 96.00%\n",
      "Epoch 5/5, Train Loss: 0.6976, Val Loss: 5.7767, Val Accuracy: 92.00%\n",
      "Model 4 Test Accuracy: 84.62%\n",
      "\n",
      "Training Model 5 with Hidden Size: 128, Learning Rate: 0.0005\n",
      "Epoch 1/5, Train Loss: 3.6304, Val Loss: 0.7571, Val Accuracy: 96.00%\n",
      "Epoch 2/5, Train Loss: 1.1782, Val Loss: 0.3270, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 0.9128, Val Loss: 0.0962, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 0.4011, Val Loss: 1.6017, Val Accuracy: 92.00%\n",
      "Epoch 5/5, Train Loss: 0.2533, Val Loss: 0.0004, Val Accuracy: 100.00%\n",
      "Model 5 Test Accuracy: 92.31%\n",
      "\n",
      "Training Model 6 with Hidden Size: 256, Learning Rate: 0.0005\n",
      "Epoch 1/5, Train Loss: 1.6780, Val Loss: 0.1347, Val Accuracy: 96.00%\n",
      "Epoch 2/5, Train Loss: 3.8953, Val Loss: 1.5860, Val Accuracy: 96.00%\n",
      "Epoch 3/5, Train Loss: 2.5359, Val Loss: 4.2388, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 2.6673, Val Loss: 4.1554, Val Accuracy: 92.00%\n",
      "Epoch 5/5, Train Loss: 3.9148, Val Loss: 0.0000, Val Accuracy: 100.00%\n",
      "Model 6 Test Accuracy: 88.46%\n",
      "\n",
      "Training Model 7 with Hidden Size: 64, Learning Rate: 0.0001\n",
      "Epoch 1/5, Train Loss: 0.4464, Val Loss: 1.1243, Val Accuracy: 92.00%\n",
      "Epoch 2/5, Train Loss: 0.5619, Val Loss: 0.5275, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 0.3812, Val Loss: 0.6945, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 0.3581, Val Loss: 0.0825, Val Accuracy: 96.00%\n",
      "Epoch 5/5, Train Loss: 0.1253, Val Loss: 1.3530, Val Accuracy: 92.00%\n",
      "Model 7 Test Accuracy: 92.31%\n",
      "\n",
      "Training Model 8 with Hidden Size: 128, Learning Rate: 0.0001\n",
      "Epoch 1/5, Train Loss: 1.1175, Val Loss: 0.1784, Val Accuracy: 96.00%\n",
      "Epoch 2/5, Train Loss: 0.2588, Val Loss: 1.2567, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 0.4291, Val Loss: 0.6860, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 0.1960, Val Loss: 0.9581, Val Accuracy: 92.00%\n",
      "Epoch 5/5, Train Loss: 0.2344, Val Loss: 0.8180, Val Accuracy: 92.00%\n",
      "Model 8 Test Accuracy: 92.31%\n",
      "\n",
      "Training Model 9 with Hidden Size: 256, Learning Rate: 0.0001\n",
      "Epoch 1/5, Train Loss: 1.0422, Val Loss: 1.0313, Val Accuracy: 92.00%\n",
      "Epoch 2/5, Train Loss: 0.3164, Val Loss: 1.6469, Val Accuracy: 92.00%\n",
      "Epoch 3/5, Train Loss: 0.2432, Val Loss: 1.2881, Val Accuracy: 92.00%\n",
      "Epoch 4/5, Train Loss: 0.0989, Val Loss: 1.0944, Val Accuracy: 96.00%\n",
      "Epoch 5/5, Train Loss: 0.0611, Val Loss: 1.0883, Val Accuracy: 92.00%\n",
      "Model 9 Test Accuracy: 88.46%\n",
      "\n",
      "Final Results:\n",
      "   Model Number  Hidden Size  Learning Rate  Test Accuracy\n",
      "0             1           64         0.0010      92.307692\n",
      "1             2          128         0.0010      92.307692\n",
      "2             3          256         0.0010      88.461538\n",
      "3             4           64         0.0005      84.615385\n",
      "4             5          128         0.0005      92.307692\n",
      "5             6          256         0.0005      88.461538\n",
      "6             7           64         0.0001      92.307692\n",
      "7             8          128         0.0001      92.307692\n",
      "8             9          256         0.0001      88.461538\n"
     ]
    }
   ],
   "source": [
    "# Define a simple feedforward neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define hyperparameters for each model\n",
    "models_config = [\n",
    "    {\"hidden_size\": 64, \"learning_rate\": 0.001},\n",
    "    {\"hidden_size\": 128, \"learning_rate\": 0.001},\n",
    "    {\"hidden_size\": 256, \"learning_rate\": 0.001},\n",
    "    {\"hidden_size\": 64, \"learning_rate\": 0.0005},\n",
    "    {\"hidden_size\": 128, \"learning_rate\": 0.0005},\n",
    "    {\"hidden_size\": 256, \"learning_rate\": 0.0005},\n",
    "    {\"hidden_size\": 64, \"learning_rate\": 0.0001},\n",
    "    {\"hidden_size\": 128, \"learning_rate\": 0.0001},\n",
    "    {\"hidden_size\": 256, \"learning_rate\": 0.0001}\n",
    "]\n",
    "\n",
    "# Function to train and validate a model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# DataFrame to store results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "input_size = 224 * 224 * 3  # Input size based on image dimensions\n",
    "output_size = len(dataset.classes)  # Number of classes\n",
    "\n",
    "for i, config in enumerate(models_config):\n",
    "    print(f\"\\nTraining Model {i+1} with Hidden Size: {config['hidden_size']}, Learning Rate: {config['learning_rate']}\")\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = SimpleNN(input_size=input_size, hidden_size=config['hidden_size'], output_size=output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"), labels.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Model {i+1} Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results.append({\n",
    "        \"Model Number\": i+1,\n",
    "        \"Hidden Size\": config['hidden_size'],\n",
    "        \"Learning Rate\": config['learning_rate'],\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    })\n",
    "\n",
    "# Create DataFrame and save results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CaioGabrielAdernedeM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\CaioGabrielAdernedeM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\CaioGabrielAdernedeM/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 72.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Binary classification (COVID vs Non-COVID)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3136\n",
      "Epoch 2, Loss: 0.0295\n",
      "Epoch 3, Loss: 0.0055\n",
      "Epoch 4, Loss: 0.0039\n",
      "Epoch 5, Loss: 0.0077\n",
      "Epoch 6, Loss: 0.0010\n",
      "Epoch 7, Loss: 0.0036\n",
      "Epoch 8, Loss: 0.0021\n",
      "Epoch 9, Loss: 0.0007\n",
      "Epoch 10, Loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_labels = []\n",
    "val_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "f1 = f1_score(val_labels, val_preds)\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in C:/Users/CaioGabrielAdernedeM/OneDrive/IPB/ipb_sistemas_inteligentes/projeto_final/evaluation_set.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m eval_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/CaioGabrielAdernedeM/OneDrive/IPB/ipb_sistemas_inteligentes/projeto_final/evaluation_set\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m eval_loader \u001b[38;5;241m=\u001b[39m DataLoader(eval_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     41\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in C:/Users/CaioGabrielAdernedeM/OneDrive/IPB/ipb_sistemas_inteligentes/projeto_final/evaluation_set."
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "eval_dir = 'C:/Users/CaioGabrielAdernedeM/OneDrive/IPB/ipb_sistemas_inteligentes/projeto_final/evaluation_set'\n",
    "eval_dataset = datasets.ImageFolder(root=eval_dir, transform=transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
